#!/usr/bin/env python3
"""
COMPREHENSIVE I18N SCANNER
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞—Ö–æ–¥–∏—Ç –í–°–ï t('key') –≤ –∫–æ–¥–µ, —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Å JSON, –¥–æ–±–∞–≤–ª—è–µ—Ç –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ.
"""

import json
import re
from pathlib import Path
from typing import Dict, Set, List
from collections import defaultdict

# –ü—É—Ç–∏
PROJECT_ROOT = Path('apps/frontend/src')
LOCALES_DIR = Path('apps/frontend/src/locales')
LANGUAGES = ['ru', 'en', 'uz', 'tg', 'ky']

# –ë–∞–∑–æ–≤—ã–µ –ø–µ—Ä–µ–≤–æ–¥—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —è–∑—ã–∫–∞ (–¥–ª—è –∞–≤—Ç–æ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏)
AUTO_TRANSLATIONS = {
    'en': {
        'title': 'Title', 'description': 'Description', 'name': 'Name',
        'status': 'Status', 'date': 'Date', 'address': 'Address',
        'phone': 'Phone', 'email': 'Email', 'city': 'City',
        'country': 'Country', 'submit': 'Submit', 'cancel': 'Cancel',
        'save': 'Save', 'edit': 'Edit', 'delete': 'Delete',
        'close': 'Close', 'open': 'Open', 'add': 'Add',
        'remove': 'Remove', 'update': 'Update', 'create': 'Create',
        'loading': 'Loading...', 'error': 'Error', 'success': 'Success',
    },
    'uz': {
        'title': 'Sarlavha', 'description': 'Tavsif', 'name': 'Ism',
        'status': 'Holat', 'date': 'Sana', 'address': 'Manzil',
        'phone': 'Telefon', 'email': 'Email', 'city': 'Shahar',
        'country': 'Mamlakat', 'submit': 'Yuborish', 'cancel': 'Bekor qilish',
        'save': 'Saqlash', 'edit': 'Tahrirlash', 'delete': "O'chirish",
        'close': 'Yopish', 'open': 'Ochish', 'add': "Qo'shish",
        'remove': 'Olib tashlash', 'update': 'Yangilash', 'create': 'Yaratish',
        'loading': 'Yuklanmoqda...', 'error': 'Xato', 'success': 'Muvaffaqiyat',
    },
    'tg': {
        'title': '–°–∞—Ä–ª–∞–≤“≥–∞', 'description': '–¢–∞–≤—Å–∏—Ñ', 'name': '–ù–æ–º',
        'status': '–í–∞–∑—ä–∏—è—Ç', 'date': '–°–∞–Ω–∞', 'address': '–°—É—Ä–æ“ì–∞',
        'phone': '–¢–µ–ª–µ—Ñ–æ–Ω', 'email': '–ü–æ—á—Ç–∞', 'city': '–®–∞“≥—Ä',
        'country': '–ö–∏—à–≤–∞—Ä', 'submit': '–§–∏—Ä–∏—Å—Ç–æ–¥–∞–Ω', 'cancel': '–ë–µ–∫–æ—Ä –∫–∞—Ä–¥–∞–Ω',
        'save': '–ó–∞—Ö–∏—Ä–∞ –∫–∞—Ä–¥–∞–Ω', 'edit': '–¢–∞“≥—Ä–∏—Ä', 'delete': '–ù–µ—Å—Ç –∫–∞—Ä–¥–∞–Ω',
        'close': '–ü”Ø—à–∏–¥–∞–Ω', 'open': '–ö—É—à–æ–¥–∞–Ω', 'add': '–ò–ª–æ–≤–∞ –∫–∞—Ä–¥–∞–Ω',
        'remove': '–•–æ—Ä–∏“∑ –∫–∞—Ä–¥–∞–Ω', 'update': '–ù–∞–≤—Å–æ–∑”£', 'create': '–≠“∑–æ–¥ –∫–∞—Ä–¥–∞–Ω',
        'loading': '–ë–æ—Ä –º–µ—à–∞–≤–∞–¥...', 'error': '–•–∞—Ç–æ', 'success': '–ú—É–≤–∞—Ñ—Ñ–∞“õ–∏—è—Ç',
    },
    'ky': {
        'title': '–ê—Ç–∞–ª—ã—à—ã', 'description': '–°“Ø—Ä”©—Ç—Ç”©–º”©', 'name': '–ê—Ç—ã',
        'status': '–°—Ç–∞—Ç—É—Å', 'date': '–ö“Ø–Ω“Ø', 'address': '–î–∞—Ä–µ–≥–∏',
        'phone': '–¢–µ–ª–µ—Ñ–æ–Ω', 'email': '–ü–æ—á—Ç–∞', 'city': '–®–∞–∞—Ä',
        'country': '”®–ª–∫”©', 'submit': '–ñ”©–Ω”©—Ç“Ø“Ø', 'cancel': '–ñ–æ–∫–∫–æ —á—ã–≥–∞—Ä—É—É',
        'save': '–°–∞–∫—Ç–æ–æ', 'edit': '–û“£–¥–æ–æ', 'delete': '”®—á“Ø—Ä“Ø“Ø',
        'close': '–ñ–∞–±—É—É', 'open': '–ê—á—É—É', 'add': '–ö–æ—à—É—É',
        'remove': '–ê–ª—ã–ø —Å–∞–ª—É—É', 'update': '–ñ–∞“£—ã—Ä—Ç—É—É', 'create': '–¢“Ø–∑“Ø“Ø',
        'loading': '–ñ“Ø–∫—Ç”©–ª“Ø“Ø–¥”©...', 'error': '–ö–∞—Ç–∞', 'success': '–ò–π–≥–∏–ª–∏–∫',
    },
}

def find_all_translation_keys() -> Set[str]:
    """–ù–∞—Ö–æ–¥–∏—Ç –í–°–ï –∫–ª—é—á–∏ t('key') –≤ –∫–æ–¥–µ."""
    keys = set()

    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ t('key') –∏ t("key")
    patterns = [
        r't\([\'"]([^\'"]+)[\'"]\)',  # t('key') –∏–ª–∏ t("key")
        r't\([\'"]([^\'"]+)[\'"],',   # t('key',
        r'titleKey:\s*[\'"]([^\'"]+)[\'"]',  # titleKey: 'key'
        r'descKey:\s*[\'"]([^\'"]+)[\'"]',   # descKey: 'key'
        r'labelKey:\s*[\'"]([^\'"]+)[\'"]',  # labelKey: 'key'
    ]

    compiled_patterns = [re.compile(p) for p in patterns]

    # –°–∫–∞–Ω–∏—Ä—É–µ–º –≤—Å–µ .tsx –∏ .ts —Ñ–∞–π–ª—ã
    for file_path in PROJECT_ROOT.rglob('*.tsx'):
        try:
            content = file_path.read_text(encoding='utf-8')
            for pattern in compiled_patterns:
                matches = pattern.findall(content)
                keys.update(matches)
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {file_path}: {e}")

    for file_path in PROJECT_ROOT.rglob('*.ts'):
        if file_path.name.endswith('.test.ts') or file_path.name.endswith('.spec.ts'):
            continue
        try:
            content = file_path.read_text(encoding='utf-8')
            for pattern in compiled_patterns:
                matches = pattern.findall(content)
                keys.update(matches)
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {file_path}: {e}")

    return keys

def load_json_keys(locale: str) -> Set[str]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –∫–ª—é—á–∏ –∏–∑ JSON —Ñ–∞–π–ª–∞ (–≤–∫–ª—é—á–∞—è –≤–ª–æ–∂–µ–Ω–Ω—ã–µ)."""
    locale_file = LOCALES_DIR / f'{locale}.json'

    if not locale_file.exists():
        return set()

    data = json.load(open(locale_file, encoding='utf-8'))

    def extract_keys(obj, prefix=''):
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ –∫–ª—é—á–∏ –≤–∫–ª—é—á–∞—è –≤–ª–æ–∂–µ–Ω–Ω—ã–µ."""
        keys = set()
        for key, value in obj.items():
            full_key = f'{prefix}.{key}' if prefix else key
            keys.add(full_key)
            if isinstance(value, dict):
                keys.update(extract_keys(value, full_key))
        return keys

    return extract_keys(data)

def get_nested_value(data: dict, key_path: str):
    """–ü–æ–ª—É—á–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ –≤–ª–æ–∂–µ–Ω–Ω–æ–º—É –∫–ª—é—á—É 'common.status'."""
    parts = key_path.split('.')
    current = data
    for part in parts:
        if isinstance(current, dict) and part in current:
            current = current[part]
        else:
            return None
    return current

def set_nested_value(data: dict, key_path: str, value):
    """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ –≤–ª–æ–∂–µ–Ω–Ω–æ–º—É –∫–ª—é—á—É 'common.status'."""
    parts = key_path.split('.')
    current = data

    for part in parts[:-1]:
        if part not in current:
            current[part] = {}
        elif not isinstance(current[part], dict):
            # –ï—Å–ª–∏ –Ω–∞ —ç—Ç–æ–º –ø—É—Ç–∏ —É–∂–µ –µ—Å—Ç—å —Å—Ç—Ä–æ–∫–∞/–ø—Ä–∏–º–∏—Ç–∏–≤ - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —ç—Ç–æ—Ç –∫–ª—é—á
            print(f"      ‚ö†Ô∏è  –ö–æ–Ω—Ñ–ª–∏–∫—Ç: {key_path} (–ø—É—Ç—å –∑–∞–Ω—è—Ç –ø—Ä–∏–º–∏—Ç–∏–≤–æ–º)")
            return
        current = current[part]

    # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–¥ —É—Å—Ç–∞–Ω–æ–≤–∫–æ–π
    if not isinstance(current, dict):
        print(f"      ‚ö†Ô∏è  –ö–æ–Ω—Ñ–ª–∏–∫—Ç: {key_path} (—Ç–µ–∫—É—â–∏–π —É–∑–µ–ª –Ω–µ dict)")
        return

    current[parts[-1]] = value

def auto_translate_key(key: str, locale: str, ru_value: str) -> str:
    """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–µ—Ä–µ–≤–æ–¥ –∫–ª—é—á–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤."""
    # –ü–æ—Å–ª–µ–¥–Ω—è—è —á–∞—Å—Ç—å –∫–ª—é—á–∞
    last_part = key.split('.')[-1]

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–ª–æ–≤–∞—Ä—å –∞–≤—Ç–æ–ø–µ—Ä–µ–≤–æ–¥–æ–≤
    if last_part.lower() in AUTO_TRANSLATIONS.get(locale, {}):
        return AUTO_TRANSLATIONS[locale][last_part.lower()]

    # –ï—Å–ª–∏ —ç—Ç–æ —Å–∏—Å—Ç–µ–º–Ω—ã–π/–∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∏–π –∫–ª—é—á - –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
    if any(ord(c) > 127 for c in last_part):
        return ru_value

    # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é - —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è –ø–æ—Å–ª–µ–¥–Ω–µ–π —á–∞—Å—Ç–∏
    return last_part.replace('_', ' ').replace('-', ' ').title()

def main():
    print("üîç COMPREHENSIVE I18N SCANNER")
    print("=" * 70)

    # –®–∞–≥ 1: –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –∫–ª—é—á–∏ –≤ –∫–æ–¥–µ
    print("\nüìù –®–∞–≥ 1: –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞...")
    code_keys = find_all_translation_keys()
    print(f"   –ù–∞–π–¥–µ–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª—é—á–µ–π: {len(code_keys)}")

    # –®–∞–≥ 2: –î–ª—è –∫–∞–∂–¥–æ–≥–æ —è–∑—ã–∫–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∫–ª—é—á–∏
    print("\nüìä –®–∞–≥ 2: –ê–Ω–∞–ª–∏–∑ –ø–æ —è–∑—ã–∫–∞–º...")

    missing_by_locale = {}

    for locale in LANGUAGES:
        json_keys = load_json_keys(locale)
        missing = code_keys - json_keys
        missing_by_locale[locale] = missing

        print(f"\n   {locale.upper()}:")
        print(f"   - –í JSON: {len(json_keys)} –∫–ª—é—á–µ–π")
        print(f"   - –í –∫–æ–¥–µ: {len(code_keys)} –∫–ª—é—á–µ–π")
        print(f"   - –ù–µ–¥–æ—Å—Ç–∞—ë—Ç: {len(missing)} –∫–ª—é—á–µ–π")

    # –®–∞–≥ 3: –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∫–ª—é—á–∏
    print("\n‚úçÔ∏è  –®–∞–≥ 3: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –∫–ª—é—á–µ–π...")

    for locale in LANGUAGES:
        missing = missing_by_locale[locale]

        if not missing:
            print(f"   {locale.upper()}: –í—Å–µ –∫–ª—é—á–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç ‚úì")
            continue

        locale_file = LOCALES_DIR / f'{locale}.json'
        data = json.load(open(locale_file, encoding='utf-8'))

        # –ó–∞–≥—Ä—É–∂–∞–µ–º ru.json –¥–ª—è reference
        ru_data = json.load(open(LOCALES_DIR / 'ru.json', encoding='utf-8'))

        added_count = 0
        for key in sorted(missing):
            # –ü—ã—Ç–∞–µ–º—Å—è –≤–∑—è—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ ru.json
            ru_value = get_nested_value(ru_data, key)

            if ru_value and locale == 'ru':
                # –ï—Å–ª–∏ —ç—Ç–æ ru.json –∏ –∑–Ω–∞—á–µ–Ω–∏–µ –µ—Å—Ç—å - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º (–Ω–µ –¥–æ–ª–∂–Ω–æ —Å–ª—É—á–∏—Ç—å—Å—è)
                continue

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø–µ—Ä–µ–≤–æ–¥
            if locale == 'ru':
                # –î–ª—è —Ä—É—Å—Å–∫–æ–≥–æ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —á–∞—Å—Ç—å –∫–ª—é—á–∞ –∫–∞–∫ fallback
                value = key.split('.')[-1].replace('_', ' ').replace('-', ' ').title()
            elif ru_value and isinstance(ru_value, str):
                # –ï—Å–ª–∏ –µ—Å—Ç—å —Ä—É—Å—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–≤—Ç–æ–ø–µ—Ä–µ–≤–æ–¥
                value = auto_translate_key(key, locale, ru_value)
            else:
                # –ò–Ω–∞—á–µ - —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è
                value = key.split('.')[-1].replace('_', ' ').replace('-', ' ').title()

            set_nested_value(data, key, value)
            added_count += 1

        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ
        with open(locale_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        print(f"   {locale.upper()}: +{added_count} –∫–ª—é—á–µ–π –¥–æ–±–∞–≤–ª–µ–Ω–æ ‚úì")

    print("\n" + "=" * 70)
    print("‚úÖ –°–ö–ê–ù–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")

    # –í—ã–≤–æ–¥–∏–º —Ç–æ–ø-10 –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –∫–ª—é—á–µ–π (–¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏)
    all_missing = set()
    for missing in missing_by_locale.values():
        all_missing.update(missing)

    if all_missing:
        print("\nüìã –ü—Ä–∏–º–µ—Ä—ã –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã—Ö –∫–ª—é—á–µ–π:")
        for i, key in enumerate(sorted(all_missing)[:10], 1):
            print(f"   {i}. {key}")
        if len(all_missing) > 10:
            print(f"   ... –∏ –µ—â—ë {len(all_missing) - 10} –∫–ª—é—á–µ–π")

    print("\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
    print("   1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–≤–æ–¥—ã –≤ JSON —Ñ–∞–π–ª–∞—Ö")
    print("   2. –ó–∞–º–µ–Ω–∏—Ç–µ –∞–≤—Ç–æ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–≤–æ–¥—ã –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ")
    print("   3. –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ dev —Å–µ—Ä–≤–µ—Ä –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π")

if __name__ == '__main__':
    main()
