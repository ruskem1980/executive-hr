#!/usr/bin/env python3
"""
–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –ø–µ—Ä–µ–≤–æ–¥–æ–≤ —á–µ—Ä–µ–∑ Gemini Flash

–≠—Ç–∞–ø—ã:
1. –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∫–ª—é—á–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —è–∑—ã–∫–∞
2. –ò–∑–≤–ª–µ—á—å —ç—Ç–∞–ª–æ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ ru.json
3. –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–µ—Ä–µ–≤–æ–¥—ã —á–µ—Ä–µ–∑ Gemini Flash (—ç–∫–æ–Ω–æ–º–∏—è —Ç–æ–∫–µ–Ω–æ–≤)
4. –û–±–Ω–æ–≤–∏—Ç—å JSON —Ñ–∞–π–ª—ã
5. –ó–∞–ø–∏—Å–∞—Ç—å —Ä–∞—Å—Ö–æ–¥ —Ç–æ–∫–µ–Ω–æ–≤ —á–µ—Ä–µ–∑ TokenTracker
"""

import json
import subprocess
import sys
import re
from pathlib import Path
from typing import Dict, List, Set, Any
from dataclasses import dataclass


@dataclass
class MissingTranslation:
    key: str
    ru_value: str
    nested_path: List[str]


class TranslationFixer:
    def __init__(self, locales_dir: Path, reference_lang: str = "ru"):
        self.locales_dir = locales_dir
        self.reference_lang = reference_lang
        self.translations = {}
        self.missing_by_lang = {}
        self.gemini_bridge = Path(__file__).parent.parent / ".claude" / "helpers" / "gemini-bridge.sh"

    def load_translations(self):
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –≤—Å–µ JSON —Ñ–∞–π–ª—ã"""
        for file in self.locales_dir.glob("*.json"):
            lang = file.stem
            with open(file, 'r', encoding='utf-8') as f:
                self.translations[lang] = json.load(f)

    def flatten_dict(self, d: Dict, parent_key: str = '') -> Dict[str, str]:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ –ø–ª–æ—Å–∫–∏–π dict"""
        items = []
        for k, v in d.items():
            new_key = f"{parent_key}.{k}" if parent_key else k
            if isinstance(v, dict):
                items.extend(self.flatten_dict(v, new_key).items())
            else:
                items.append((new_key, str(v) if v is not None else ""))
        return dict(items)

    def get_nested_value(self, data: Dict, key_path: str) -> Any:
        """–ü–æ–ª—É—á–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ dot-notation"""
        keys = key_path.split('.')
        value = data
        for k in keys:
            if isinstance(value, dict) and k in value:
                value = value[k]
            else:
                return None
        return value

    def set_nested_value(self, data: Dict, key_path: str, value: Any):
        """–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ dot-notation"""
        keys = key_path.split('.')
        current = data

        for i, k in enumerate(keys[:-1]):
            if k not in current:
                current[k] = {}
            elif not isinstance(current[k], dict):
                # –ö–æ–Ω—Ñ–ª–∏–∫—Ç: –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —É–∑–µ–ª –Ω–µ dict
                print(f"  ‚ö†Ô∏è  –ö–æ–Ω—Ñ–ª–∏–∫—Ç: {'.'.join(keys[:i+1])} –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –æ–±—ä–µ–∫—Ç–æ–º")
                return
            current = current[k]

        current[keys[-1]] = value

    def find_missing_keys(self):
        """–ù–∞–π—Ç–∏ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∫–ª—é—á–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —è–∑—ã–∫–∞"""
        ref_flat = self.flatten_dict(self.translations[self.reference_lang])
        ref_keys = set(ref_flat.keys())

        for lang in self.translations:
            if lang == self.reference_lang:
                continue

            lang_flat = self.flatten_dict(self.translations[lang])
            lang_keys = set(lang_flat.keys())

            missing = ref_keys - lang_keys
            if missing:
                self.missing_by_lang[lang] = [
                    MissingTranslation(
                        key=key,
                        ru_value=ref_flat[key],
                        nested_path=key.split('.')
                    )
                    for key in sorted(missing)
                ]

    def generate_translations_batch(self, lang: str, batch: List[MissingTranslation], lang_full_name: str) -> Dict[str, str]:
        """
        –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–µ—Ä–µ–≤–æ–¥—ã –¥–ª—è –±–∞—Ç—á–∞ —á–µ—Ä–µ–∑ Gemini Flash

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict: {key: translated_value}
        """
        # –§–æ—Ä–º–∏—Ä—É–µ–º JSON —Å –∫–ª—é—á–∞–º–∏ –∏ —Ä—É—Å—Å–∫–∏–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        translations_json = {item.key: item.ru_value for item in batch}

        # –ü—Ä–æ–º–ø—Ç –¥–ª—è Gemini
        prompt = f"""–¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–≤.

–ó–∞–¥–∞—á–∞: –ü–µ—Ä–µ–≤–µ—Å—Ç–∏ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ —Å —Ä—É—Å—Å–∫–æ–≥–æ –Ω–∞ {lang_full_name} —è–∑—ã–∫.

–ö–æ–Ω—Ç–µ–∫—Å—Ç: –≠—Ç–æ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –º–æ–±–∏–ª—å–Ω–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è MigrantHub ‚Äî –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–π –ø–æ–º–æ—â–∏ –º–∏–≥—Ä–∞–Ω—Ç–∞–º –≤ –†–æ—Å—Å–∏–∏.

–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (JSON):
{json.dumps(translations_json, ensure_ascii=False, indent=2)}

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
1. –ü–µ—Ä–µ–≤–µ—Å—Ç–∏ –¢–û–õ–¨–ö–û –∑–Ω–∞—á–µ–Ω–∏—è, –∫–ª—é—á–∏ –Ω–µ —Ç—Ä–æ–≥–∞—Ç—å
2. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã {{{{var}}}} –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
3. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (\\n, –ø—Ä–æ–±–µ–ª—ã)
4. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π —Å—Ç–∏–ª—å –¥–ª—è –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤
5. –î–ª—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ (–ø–∞—Ç–µ–Ω—Ç, –†–í–ü, –í–ù–ñ, –°–ù–ò–õ–°, –ò–ù–ù) –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–±—â–µ–ø—Ä–∏–Ω—è—Ç—ã–µ —Ñ–æ—Ä–º—ã

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞: –¢–û–õ–¨–ö–û JSON —Å –ø–µ—Ä–µ–≤–µ–¥—ë–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏, –±–µ–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤.
–ü—Ä–∏–º–µ—Ä:
{{
  "key1": "–ø–µ—Ä–µ–≤–æ–¥1",
  "key2": "–ø–µ—Ä–µ–≤–æ–¥2"
}}

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON, –±–µ–∑ markdown –±–ª–æ–∫–æ–≤, –±–µ–∑ —Ç–µ–∫—Å—Ç–∞ –¥–æ/–ø–æ—Å–ª–µ."""

        # –ó–∞–ø—É—Å–∫ Gemini Flash —á–µ—Ä–µ–∑ bridge
        print(f"    ü§ñ –í—ã–∑–æ–≤ Gemini Flash –¥–ª—è {len(batch)} –∫–ª—é—á–µ–π...")

        try:
            result = subprocess.run(
                ["bash", str(self.gemini_bridge), "flash", prompt],
                capture_output=True,
                text=True,
                timeout=120
            )

            if result.returncode != 0:
                print(f"    ‚ùå –û—à–∏–±–∫–∞ –≤—ã–∑–æ–≤–∞ Gemini: {result.stderr}")
                return {}

            output = result.stdout.strip()

            # –£–±—Ä–∞—Ç—å markdown –±–ª–æ–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
            output = re.sub(r'^```json\s*', '', output)
            output = re.sub(r'\s*```$', '', output)
            output = output.strip()

            # –ü–∞—Ä—Å–∏–Ω–≥ JSON
            translated = json.loads(output)

            print(f"    ‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(translated)} –ø–µ—Ä–µ–≤–æ–¥–æ–≤")
            return translated

        except subprocess.TimeoutExpired:
            print(f"    ‚ùå –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –≤—ã–∑–æ–≤–µ Gemini")
            return {}
        except json.JSONDecodeError as e:
            print(f"    ‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –æ—Ç Gemini: {e}")
            print(f"    –û—Ç–≤–µ—Ç: {output[:200]}...")
            return {}
        except Exception as e:
            print(f"    ‚ùå –û—à–∏–±–∫–∞: {e}")
            return {}

    def fix_language(self, lang: str, lang_full_name: str):
        """–ò—Å–ø—Ä–∞–≤–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥—ã –¥–ª—è –æ–¥–Ω–æ–≥–æ —è–∑—ã–∫–∞"""
        if lang not in self.missing_by_lang:
            print(f"  ‚úÖ {lang}: –í—Å–µ –ø–µ—Ä–µ–≤–æ–¥—ã –Ω–∞ –º–µ—Å—Ç–µ")
            return 0

        missing = self.missing_by_lang[lang]
        print(f"  üîß {lang}: –ù–µ–¥–æ—Å—Ç–∞—ë—Ç {len(missing)} –ø–µ—Ä–µ–≤–æ–¥–æ–≤")

        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –±–∞—Ç—á–∏ –ø–æ 50 –∫–ª—é—á–µ–π (—á—Ç–æ–±—ã –Ω–µ –ø—Ä–µ–≤—ã—à–∞—Ç—å –ª–∏–º–∏—Ç—ã –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)
        batch_size = 50
        batches = [missing[i:i + batch_size] for i in range(0, len(missing), batch_size)]

        all_translations = {}

        for i, batch in enumerate(batches, 1):
            print(f"    üì¶ –ë–∞—Ç—á {i}/{len(batches)} ({len(batch)} –∫–ª—é—á–µ–π)")
            translated = self.generate_translations_batch(lang, batch, lang_full_name)
            all_translations.update(translated)

        # –ü—Ä–∏–º–µ–Ω–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥—ã –∫ JSON
        if all_translations:
            print(f"    üíæ –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ {len(all_translations)} –ø–µ—Ä–µ–≤–æ–¥–æ–≤...")
            updated_data = self.translations[lang].copy()

            for key, value in all_translations.items():
                self.set_nested_value(updated_data, key, value)

            # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å JSON
            output_file = self.locales_dir / f"{lang}.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(updated_data, f, ensure_ascii=False, indent=2)

            print(f"    ‚úÖ –§–∞–π–ª –æ–±–Ω–æ–≤–ª—ë–Ω: {output_file}")
            return len(all_translations)
        else:
            print(f"    ‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–µ—Ä–µ–≤–æ–¥—ã")
            return 0

    def fix_all(self):
        """–ò—Å–ø—Ä–∞–≤–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥—ã –¥–ª—è –≤—Å–µ—Ö —è–∑—ã–∫–æ–≤"""
        print("=" * 80)
        print("–ì–ï–ù–ï–†–ê–¶–ò–Ø –ù–ï–î–û–°–¢–ê–Æ–©–ò–• –ü–ï–†–ï–í–û–î–û–í")
        print("=" * 80)
        print()

        self.load_translations()
        print(f"üì¶ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —è–∑—ã–∫–æ–≤: {', '.join(sorted(self.translations.keys()))}")
        print()

        self.find_missing_keys()

        if not self.missing_by_lang:
            print("‚úÖ –í—Å–µ –ø–µ—Ä–µ–≤–æ–¥—ã –Ω–∞ –º–µ—Å—Ç–µ!")
            return {}

        print("üîç –ù–∞–π–¥–µ–Ω—ã –ø—Ä–æ–±–µ–ª—ã:")
        for lang, missing in self.missing_by_lang.items():
            print(f"  - {lang}: {len(missing)} –∫–ª—é—á–µ–π")
        print()

        # –ú–∞–ø–ø–∏–Ω–≥ —è–∑—ã–∫–æ–≤—ã—Ö –∫–æ–¥–æ–≤ –Ω–∞ –ø–æ–ª–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è
        lang_names = {
            "en": "–∞–Ω–≥–ª–∏–π—Å–∫–∏–π (English)",
            "uz": "—É–∑–±–µ–∫—Å–∫–∏–π (O'zbek tili, –ª–∞—Ç–∏–Ω–∏—Ü–∞)",
            "tg": "—Ç–∞–¥–∂–∏–∫—Å–∫–∏–π (—Ç–æ“∑–∏–∫”£)",
            "ky": "–∫–∏—Ä–≥–∏–∑—Å–∫–∏–π (–∫—ã—Ä–≥—ã–∑—á–∞)"
        }

        stats = {}

        for lang in sorted(self.missing_by_lang.keys()):
            lang_full = lang_names.get(lang, lang)
            print(f"üåç –û–±—Ä–∞–±–æ—Ç–∫–∞: {lang} ({lang_full})")
            fixed_count = self.fix_language(lang, lang_full)
            stats[lang] = fixed_count
            print()

        return stats


def estimate_tokens(translations_count: int, avg_value_length: int = 50) -> tuple:
    """
    –û—Ü–µ–Ω–∏—Ç—å —Ä–∞—Å—Ö–æ–¥ —Ç–æ–∫–µ–Ω–æ–≤

    Gemini Flash:
    - Input: –ø—Ä–æ–º–ø—Ç + JSON –∫–ª—é—á–µ–π (~200 —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∞ –∫–ª—é—á —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º)
    - Output: JSON –ø–µ—Ä–µ–≤–æ–¥–æ–≤ (~150 —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∞ –∫–ª—é—á)
    """
    input_per_key = 200
    output_per_key = 150

    total_input = translations_count * input_per_key
    total_output = translations_count * output_per_key

    return (total_input, total_output)


def main():
    locales_dir = Path(__file__).parent.parent / "apps" / "frontend" / "src" / "locales"

    if not locales_dir.exists():
        print(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {locales_dir}")
        return 1

    fixer = TranslationFixer(locales_dir)
    stats = fixer.fix_all()

    if stats:
        print("=" * 80)
        print("–ò–¢–û–ì–ò –ì–ï–ù–ï–†–ê–¶–ò–ò")
        print("=" * 80)
        print()

        total_fixed = sum(stats.values())
        for lang, count in stats.items():
            print(f"  ‚úÖ {lang}: {count} –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –¥–æ–±–∞–≤–ª–µ–Ω–æ")

        print()
        print(f"üìä –í—Å–µ–≥–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: {total_fixed} –ø–µ—Ä–µ–≤–æ–¥–æ–≤")
        print()

        # –û—Ü–µ–Ω–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤
        est_input, est_output = estimate_tokens(total_fixed)
        print("üí∞ –û—Ü–µ–Ω–∫–∞ —Ä–∞—Å—Ö–æ–¥–∞ —Ç–æ–∫–µ–Ω–æ–≤ (Gemini Flash):")
        print(f"  - Input:  ~{est_input:,} —Ç–æ–∫–µ–Ω–æ–≤")
        print(f"  - Output: ~{est_output:,} —Ç–æ–∫–µ–Ω–æ–≤")
        print(f"  - –°—Ç–æ–∏–º–æ—Å—Ç—å: ~${(est_input * 0.5 + est_output * 3.0) / 1_000_000:.4f}")
        print()

        return 0
    else:
        print("‚úÖ –ù–µ—á–µ–≥–æ –∏—Å–ø—Ä–∞–≤–ª—è—Ç—å")
        return 0


if __name__ == "__main__":
    sys.exit(main())
