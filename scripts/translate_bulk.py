#!/usr/bin/env python3
"""
–ë—ã—Å—Ç—Ä—ã–π –º–∞—Å—Å–æ–≤—ã–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫ —á–µ—Ä–µ–∑ Gemini Pro.
–ü–µ—Ä–µ–≤–æ–¥–∏—Ç –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ñ—Ä–∞–∑—ã –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —è–∑—ã–∫–∞.
"""
import json
import subprocess
from pathlib import Path
from typing import Dict, Set, List

PROJECT_ROOT = Path.cwd()
LOCALES_DIR = PROJECT_ROOT / "apps" / "frontend" / "src" / "locales"

class BulkTranslator:
    def __init__(self):
        self.ru_json = self._load_json('ru')
        self.unique_phrases = set()

    def _load_json(self, lang: str) -> dict:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç JSON —Ñ–∞–π–ª"""
        path = LOCALES_DIR / f"{lang}.json"
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)

    def _save_json(self, lang: str, data: dict):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç JSON —Ñ–∞–π–ª"""
        path = LOCALES_DIR / f"{lang}.json"
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2, sort_keys=True)

    def collect_unique_phrases(self, lang: str) -> Set[str]:
        """–°–æ–±–∏—Ä–∞–µ—Ç –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ä—É—Å—Å–∫–∏–µ —Ñ—Ä–∞–∑—ã –∏–∑ –∑–∞–≥–ª—É—à–µ–∫"""
        phrases = set()
        prefix = f'[{lang.upper()}]'

        target_json = self._load_json(lang)

        def traverse(obj):
            if isinstance(obj, str):
                if obj.startswith(prefix):
                    russian_text = obj[len(prefix):].strip()
                    phrases.add(russian_text)
            elif isinstance(obj, dict):
                for value in obj.values():
                    traverse(value)
            elif isinstance(obj, list):
                for item in obj:
                    traverse(item)

        traverse(target_json)
        return phrases

    def translate_phrases_via_gemini(self, phrases: List[str], target_lang: str) -> Dict[str, str]:
        """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç —Å–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ñ—Ä–∞–∑ —á–µ—Ä–µ–∑ Gemini Pro"""
        if not phrases:
            return {}

        lang_names = {
            'en': 'English',
            'uz': 'Uzbek (Latin script)',
            'tg': 'Tajik (Cyrillic script)',
            'ky': 'Kyrgyz (Cyrillic script)'
        }

        # –°–æ–∑–¥–∞—ë–º –ø—Ä–æ–Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Ñ—Ä–∞–∑
        numbered_phrases = "\n".join(f"{i+1}. {phrase}" for i, phrase in enumerate(phrases))

        prompt = f"""Translate these {len(phrases)} Russian phrases to {lang_names[target_lang]}.

STRICT FORMAT:
- Output ONLY the translations
- One translation per line
- Keep the EXACT same order and line count
- NO numbering, NO markdown, NO explanations
- Preserve technical terms, numbers, time formats (24/7, –ü–Ω-–ü—Ç 9:00-18:00)
- Keep proper nouns unchanged

Russian phrases:
{numbered_phrases}

{lang_names[target_lang]} translations:"""

        print(f"  üîÑ –û—Ç–ø—Ä–∞–≤–∫–∞ {len(phrases)} —Ñ—Ä–∞–∑ –≤ Gemini Pro...")

        try:
            result = subprocess.run(
                ['bash', '.claude/helpers/gemini-bridge.sh', 'pro', prompt],
                capture_output=True,
                text=True,
                timeout=180
            )

            if result.returncode != 0:
                print(f"  ‚ö†Ô∏è Gemini –æ—à–∏–±–∫–∞: {result.stderr}")
                return {}

            response = result.stdout.strip()

            # –£–±–∏—Ä–∞–µ–º markdown –µ—Å–ª–∏ –µ—Å—Ç—å
            import re
            response = re.sub(r'^```.*?\n', '', response, flags=re.MULTILINE)
            response = re.sub(r'\n```$', '', response)

            # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å—Ç—Ä–æ–∫–∏
            lines = [line.strip() for line in response.split('\n') if line.strip()]

            # –°–æ–∑–¥–∞—ë–º —Å–ª–æ–≤–∞—Ä—å
            translations = {}
            for i, (phrase, translation) in enumerate(zip(phrases, lines)):
                translations[phrase] = translation

            if len(translations) != len(phrases):
                print(f"  ‚ö†Ô∏è –ü–æ–ª—É—á–µ–Ω–æ {len(translations)} –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –∏–∑ {len(phrases)}")

            return translations

        except subprocess.TimeoutExpired:
            print(f"  ‚ùå Timeout –ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ")
            return {}
        except Exception as e:
            print(f"  ‚ùå –û—à–∏–±–∫–∞: {e}")
            return {}

    def apply_translations(self, lang: str, translations: Dict[str, str]):
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç –ø–µ—Ä–µ–≤–æ–¥—ã –∫ —è–∑—ã–∫–æ–≤–æ–º—É —Ñ–∞–π–ª—É"""
        target_json = self._load_json(lang)
        prefix = f'[{lang.upper()}]'
        replaced_count = 0

        def replace_in_obj(obj):
            nonlocal replaced_count
            if isinstance(obj, str):
                if obj.startswith(prefix):
                    russian_text = obj[len(prefix):].strip()
                    if russian_text in translations:
                        replaced_count += 1
                        return translations[russian_text]
                return obj
            elif isinstance(obj, dict):
                return {k: replace_in_obj(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [replace_in_obj(item) for item in obj]
            return obj

        updated_json = replace_in_obj(target_json)
        self._save_json(lang, updated_json)

        print(f"  ‚úÖ –ó–∞–º–µ–Ω–µ–Ω–æ {replaced_count} –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –≤ {lang}.json")

    def translate_language(self, lang: str, chunk_size: int = 500):
        """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç –æ–¥–∏–Ω —è–∑—ã–∫"""
        print(f"\nüåç –ü–µ—Ä–µ–≤–æ–¥ –Ω–∞ {lang.upper()}...")

        # –°–æ–±–∏—Ä–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ñ—Ä–∞–∑—ã
        phrases = self.collect_unique_phrases(lang)
        total = len(phrases)

        if total == 0:
            print(f"  ‚úÖ –ó–∞–≥–ª—É—à–µ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            return

        print(f"  üìù –ù–∞–π–¥–µ–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ñ—Ä–∞–∑: {total}")

        # –ü–µ—Ä–µ–≤–æ–¥–∏–º —á–∞–Ω–∫–∞–º–∏ –ø–æ 500 —Ñ—Ä–∞–∑
        phrases_list = sorted(list(phrases))  # –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
        all_translations = {}

        for i in range(0, total, chunk_size):
            chunk = phrases_list[i:i + chunk_size]
            print(f"  üì¶ –ß–∞–Ω–∫ {i//chunk_size + 1}/{(total + chunk_size - 1)//chunk_size} ({len(chunk)} —Ñ—Ä–∞–∑)")

            chunk_translations = self.translate_phrases_via_gemini(chunk, lang)
            all_translations.update(chunk_translations)

        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–µ—Ä–µ–≤–æ–¥—ã
        print(f"  üíæ –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥–æ–≤...")
        self.apply_translations(lang, all_translations)

def main():
    import sys

    print("üöÄ –ó–∞–ø—É—Å–∫ –±—ã—Å—Ç—Ä–æ–≥–æ –º–∞—Å—Å–æ–≤–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–∞...")
    translator = BulkTranslator()

    languages = ['en', 'uz', 'tg', 'ky']

    if len(sys.argv) > 1:
        lang = sys.argv[1].lower()
        if lang in languages:
            languages = [lang]

    for lang in languages:
        try:
            translator.translate_language(lang, chunk_size=500)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()

    print("\n" + "="*50)
    print("‚úÖ –ü–ï–†–ï–í–û–î –ó–ê–í–ï–†–®–Å–ù")
    print("="*50)

if __name__ == '__main__':
    main()
