#!/usr/bin/env python3
"""
–ì–ª–∞–≤–Ω—ã–π workflow - –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Å–∏—Å—Ç–µ–º—ã –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–π –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏.

Workflow:
User Query ‚Üí HybridClassifier ‚Üí SmartExecutor ‚Üí ToolOrchestrator
  ‚Üí HybridReportAggregator ‚Üí complexity determination ‚Üí model selection
  ‚Üí LLM prompt ‚Üí Gemini Bridge ‚Üí response

–ê–≤—Ç–æ—Ä: PT_Standart
"""

import json
import argparse
import subprocess
import time
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from enum import Enum
from dataclasses import dataclass, asdict

from src.reporting.token_tracker import TokenTracker


# ============================================================================
# ENUMS & DATA CLASSES
# ============================================================================

class RequestType(Enum):
    """–¢–∏–ø—ã –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    SECURITY = "security"
    PERFORMANCE = "performance"
    REFACTORING = "refactoring"
    DEBUGGING = "debugging"
    TESTING = "testing"
    DOCUMENTATION = "documentation"
    ARCHITECTURE = "architecture"


class Severity(Enum):
    """–£—Ä–æ–≤–Ω–∏ –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏ –ø—Ä–æ–±–ª–µ–º"""
    LOW = "LOW"
    MEDIUM = "MEDIUM"
    HIGH = "HIGH"
    CRITICAL = "CRITICAL"


class Complexity(Enum):
    """–°–ª–æ–∂–Ω–æ—Å—Ç—å –∑–∞–¥–∞—á–∏ –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π"""
    SIMPLE = "SIMPLE"
    MEDIUM = "MEDIUM"
    COMPLEX = "COMPLEX"


@dataclass
class Issue:
    """–ù–∞–π–¥–µ–Ω–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞"""
    type: str
    severity: str
    message: str
    file: Optional[str] = None
    line: Optional[int] = None
    suggestion: Optional[str] = None


@dataclass
class Classification:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–∞"""
    primary_type: RequestType
    confidence: float
    tools: List[str]
    scope: str
    keywords: List[str]


@dataclass
class Report:
    """–ö–æ–º–ø–∞–∫—Ç–Ω—ã–π –æ—Ç—á–µ—Ç –¥–ª—è LLM"""
    summary: str
    issues: List[Issue]
    metrics: Dict
    recommendations: List[str]
    files_analyzed: int
    total_issues: int
    critical_issues: int


# ============================================================================
# HYBRID CLASSIFIER
# ============================================================================

class HybridClassifier:
    """
    –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è).

    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –∑–∞–¥–∞—á–∏, –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∏ scope –∞–Ω–∞–ª–∏–∑–∞.
    """

    def __init__(self):
        self.keywords_map = {
            RequestType.SECURITY: ["–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç", "—É—è–∑–≤–∏–º–æ—Å—Ç", "CVE", "inject", "auth", "XSS", "SQL"],
            RequestType.PERFORMANCE: ["–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç", "–æ–ø—Ç–∏–º–∏–∑", "–º–µ–¥–ª–µ–Ω–Ω", "–±—ã—Å—Ç—Ä", "–ø—Ä–æ—Ñ–∞–π–ª", "benchmark"],
            RequestType.REFACTORING: ["—Ä–µ—Ñ–∞–∫—Ç–æ—Ä", "—É–ª—É—á—à", "–ø–µ—Ä–µ–ø–∏—Å–∞", "–∫–æ–¥ —Å–º–µ–ª–ª", "DRY", "SOLID"],
            RequestType.DEBUGGING: ["–±–∞–≥", "–æ—à–∏–±–∫", "–Ω–µ —Ä–∞–±–æ—Ç–∞", "debug", "–∏—Å–ø—Ä–∞–≤", "–ø—Ä–æ–±–ª–µ–º"],
            RequestType.TESTING: ["—Ç–µ—Å—Ç", "–ø–æ–∫—Ä—ã—Ç", "unittest", "pytest", "test coverage"],
            RequestType.DOCUMENTATION: ["–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü", "docstring", "–∫–æ–º–º–µ–Ω—Ç–∞—Ä", "README"],
            RequestType.ARCHITECTURE: ["–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä", "–¥–∏–∑–∞–π–Ω", "–ø–∞—Ç—Ç–µ—Ä–Ω", "—Å—Ç—Ä—É–∫—Ç—É—Ä", "–º–æ–¥—É–ª"],
        }

        self.tools_map = {
            RequestType.SECURITY: ["bandit", "semgrep", "safety"],
            RequestType.PERFORMANCE: ["profiler", "memory_profiler", "benchmark"],
            RequestType.REFACTORING: ["radon", "pylint", "flake8"],
            RequestType.DEBUGGING: ["debugger", "logger", "tracer"],
            RequestType.TESTING: ["pytest", "coverage", "test_analyzer"],
            RequestType.DOCUMENTATION: ["doc_analyzer", "pydoc"],
            RequestType.ARCHITECTURE: ["structure_analyzer", "dependency_graph"],
        }

    def classify(self, user_query: str) -> Classification:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        query_lower = user_query.lower()

        # –ü–æ–¥—Å—á–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        scores = {}
        matched_keywords = []

        for req_type, keywords in self.keywords_map.items():
            score = sum(1 for kw in keywords if kw in query_lower)
            scores[req_type] = score
            if score > 0:
                matched_keywords.extend([kw for kw in keywords if kw in query_lower])

        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ç–∏–ø–∞
        if not scores or max(scores.values()) == 0:
            primary_type = RequestType.DEBUGGING  # default
            confidence = 0.5
        else:
            primary_type = max(scores, key=scores.get)
            total_keywords = sum(len(kws) for kws in self.keywords_map.values())
            confidence = min(scores[primary_type] / 5.0, 1.0)  # normalize

        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ scope
        scope = "module"  # default
        if "–≤—Å–µ" in query_lower or "–≤–µ—Å—å –ø—Ä–æ–µ–∫—Ç" in query_lower:
            scope = "project"
        elif "—Ñ–∞–π–ª" in query_lower or "—Ñ—É–Ω–∫—Ü–∏" in query_lower:
            scope = "file"

        # –ü–æ–¥–±–æ—Ä –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        tools = self.tools_map.get(primary_type, ["generic_analyzer"])

        return Classification(
            primary_type=primary_type,
            confidence=confidence,
            tools=tools,
            scope=scope,
            keywords=matched_keywords[:5]  # top 5
        )


# ============================================================================
# SMART EXECUTOR (Mock)
# ============================================================================

class SmartExecutor:
    """
    –£–º–Ω—ã–π –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ (Mock –≤–µ—Ä—Å–∏—è).

    –í —Ä–µ–∞–ª—å–Ω–æ–π –≤–µ—Ä—Å–∏–∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã (bandit, pylint, etc).
    """

    def __init__(self, project_root: Path):
        self.project_root = project_root

    def execute(self, classification: Classification) -> Dict:
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∏ —Å–æ–±–∏—Ä–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"""
        print(f"üîß Executing tools: {', '.join(classification.tools)}")

        # Mock —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
        issues = []

        if RequestType.SECURITY in [classification.primary_type]:
            issues.extend([
                Issue(
                    type="SQL_INJECTION",
                    severity=Severity.HIGH.value,
                    message="Possible SQL injection vulnerability",
                    file="src/database/queries.py",
                    line=42,
                    suggestion="Use parameterized queries"
                ),
                Issue(
                    type="HARDCODED_PASSWORD",
                    severity=Severity.CRITICAL.value,
                    message="Hardcoded password detected",
                    file="src/config/settings.py",
                    line=15,
                    suggestion="Use environment variables"
                ),
            ])

        if RequestType.PERFORMANCE in [classification.primary_type]:
            issues.extend([
                Issue(
                    type="INEFFICIENT_LOOP",
                    severity=Severity.MEDIUM.value,
                    message="Nested loop with O(n¬≤) complexity",
                    file="src/api/handlers.py",
                    line=128,
                    suggestion="Use dictionary lookup instead"
                ),
                Issue(
                    type="MEMORY_LEAK",
                    severity=Severity.HIGH.value,
                    message="Potential memory leak in cache",
                    file="src/cache/manager.py",
                    line=67,
                    suggestion="Implement cache eviction policy"
                ),
            ])

        # –ú–µ—Ç—Ä–∏–∫–∏
        metrics = {
            "execution_time_ms": 1234,
            "files_scanned": 45,
            "lines_of_code": 5678,
            "tools_used": len(classification.tools)
        }

        return {
            "issues": [asdict(issue) for issue in issues],
            "metrics": metrics
        }


# ============================================================================
# HYBRID REPORT AGGREGATOR
# ============================================================================

class HybridReportAggregator:
    """
    –ê–≥—Ä–µ–≥–∞—Ç–æ—Ä –æ—Ç—á–µ—Ç–æ–≤ - —Å–æ–∑–¥–∞–µ—Ç –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π –æ—Ç—á–µ—Ç –¥–ª—è LLM.

    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—Å–µ—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –≤ –µ–¥–∏–Ω—ã–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç—á–µ—Ç.
    """

    def aggregate(self, classification: Classification, executor_results: Dict) -> Report:
        """–°–æ–∑–¥–∞–µ—Ç –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π –æ—Ç—á–µ—Ç"""
        issues_data = executor_results.get("issues", [])
        metrics = executor_results.get("metrics", {})

        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ –æ–±—ä–µ–∫—Ç—ã Issue
        issues = [Issue(**issue_dict) for issue_dict in issues_data]

        # –ü–æ–¥—Å—á–µ—Ç –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º
        critical_count = sum(1 for issue in issues if issue.severity == Severity.CRITICAL.value)

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è summary
        summary = f"Found {len(issues)} issues"
        if critical_count > 0:
            summary += f", including {critical_count} CRITICAL"

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        recommendations = []
        if critical_count > 0:
            recommendations.append("Address CRITICAL issues immediately")
        if len(issues) > 10:
            recommendations.append("Consider incremental refactoring")
        if classification.primary_type == RequestType.SECURITY:
            recommendations.append("Run security audit before deployment")

        return Report(
            summary=summary,
            issues=issues,
            metrics=metrics,
            recommendations=recommendations,
            files_analyzed=metrics.get("files_scanned", 0),
            total_issues=len(issues),
            critical_issues=critical_count
        )


# ============================================================================
# COMPLEXITY DETERMINATION & MODEL SELECTION
# ============================================================================

def determine_complexity(report: Report) -> Complexity:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∑–∞–¥–∞—á–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç—á–µ—Ç–∞.

    –ü—Ä–∞–≤–∏–ª–∞:
    - SIMPLE: 1-2 –ø—Ä–æ–±–ª–µ–º—ã, –≤—Å–µ LOW/MEDIUM
    - MEDIUM: 3-10 –ø—Ä–æ–±–ª–µ–º –∏–ª–∏ –µ—Å—Ç—å HIGH
    - COMPLEX: >10 –ø—Ä–æ–±–ª–µ–º –∏–ª–∏ –µ—Å—Ç—å CRITICAL
    """
    issues_count = report.total_issues
    has_critical = report.critical_issues > 0
    has_high = any(issue.severity == Severity.HIGH.value for issue in report.issues)

    if has_critical or issues_count > 10:
        return Complexity.COMPLEX
    elif issues_count > 3 or has_high:
        return Complexity.MEDIUM
    else:
        return Complexity.SIMPLE


def select_model(complexity: Complexity) -> str:
    """
    –í—ã–±–∏—Ä–∞–µ—Ç –º–æ–¥–µ–ª—å Gemini –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏.

    –ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è:
    - SIMPLE ‚Üí flash ($0.50/$3.00 per 1M tokens)
    - MEDIUM ‚Üí pro ($2.00/$12.00 per 1M tokens)
    - COMPLEX ‚Üí pro (–∏—Å–ø–æ–ª—å–∑—É–µ–º –ª—É—á—à—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é –º–æ–¥–µ–ª—å –≤ Gemini)

    –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –î–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á Opus –¥–æ–ª–∂–µ–Ω —Ä–∞–±–æ—Ç–∞—Ç—å
    –Ω–∞–ø—Ä—è–º—É—é –±–µ–∑ –¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–∏—è, –Ω–æ —ç—Ç–æ –≤—ã—Ö–æ–¥–∏—Ç –∑–∞ —Ä–∞–º–∫–∏ workflow.
    """
    model_map = {
        Complexity.SIMPLE: "flash",
        Complexity.MEDIUM: "pro",
        Complexity.COMPLEX: "pro",  # –∏—Å–ø–æ–ª—å–∑—É–µ–º Pro –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á –≤ Gemini
    }
    return model_map[complexity]


# ============================================================================
# PROMPT BUILDING
# ============================================================================

def build_llm_prompt(user_query: str, report: Report, classification: Classification) -> str:
    """
    –°—Ç—Ä–æ–∏—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM.

    –í–∫–ª—é—á–∞–µ—Ç:
    - –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    - –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    - –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è LLM
    """
    req_type = classification.primary_type.value

    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –≤ JSON
    report_dict = {
        "summary": report.summary,
        "total_issues": report.total_issues,
        "critical_issues": report.critical_issues,
        "files_analyzed": report.files_analyzed,
        "issues": [asdict(issue) for issue in report.issues],
        "metrics": report.metrics,
        "recommendations": report.recommendations,
    }

    prompt = f"""–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ Python –∏ {req_type}.

–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç: "{user_query}"

–Ø —É–∂–µ –∑–∞–ø—É—Å—Ç–∏–ª –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:

```json
{json.dumps(report_dict, indent=2, ensure_ascii=False)}
```

–ù–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å:
1. –ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
2. –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—é (–ø—Ä–∏–æ—Ä–∏—Ç–µ–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫)
3. –ü—Ä–∏–º–µ—Ä—ã –∫–æ–¥–∞ –¥–ª—è —Ç–æ–ø-3 –ø—Ä–æ–±–ª–µ–º (–µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ)

–ë—É–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–µ–Ω –∏ –ø—Ä–∞–∫—Ç–∏—á–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–π –¥–∞–Ω–Ω—ã–µ –∏–∑ –æ—Ç—á–µ—Ç–∞, –Ω–µ –≤—ã–¥—É–º—ã–≤–∞–π."""

    return prompt


# ============================================================================
# GEMINI BRIDGE
# ============================================================================

class GeminiBridge:
    """
    –ú–æ—Å—Ç –¥–ª—è –≤—ã–∑–æ–≤–∞ Gemini –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ CLI —Å–∫—Ä–∏–ø—Ç.

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç .claude/helpers/gemini-bridge.sh –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å Gemini API.
    """

    def __init__(self, bridge_script: Optional[Path] = None, use_mock: bool = False):
        if bridge_script is None:
            self.bridge_script = Path(__file__).parent.parent / ".claude" / "helpers" / "gemini-bridge.sh"
        else:
            self.bridge_script = bridge_script

        self.use_mock = use_mock

        if not self.bridge_script.exists():
            print(f"‚ö†Ô∏è  Warning: gemini-bridge.sh not found at {self.bridge_script}")
            print("    Will use mock response")
            self.use_mock = True
        else:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –¥–æ—Å—Ç—É–ø–µ–Ω –ª–∏ gemini CLI
            try:
                result = subprocess.run(
                    ["which", "gemini"],
                    capture_output=True,
                    timeout=2
                )
                if result.returncode != 0:
                    print("‚ö†Ô∏è  Warning: 'gemini' CLI not found in PATH")
                    print("    Will use mock response")
                    self.use_mock = True
            except Exception:
                self.use_mock = True

    def call(self, model: str, prompt: str) -> str:
        """
        –í—ã–∑—ã–≤–∞–µ—Ç Gemini –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ bridge —Å–∫—Ä–∏–ø—Ç.

        Args:
            model: "flash" –∏–ª–∏ "pro"
            prompt: –ø–æ–ª–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º

        Returns:
            –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏
        """
        if self.use_mock:
            return self._mock_response(model, prompt)

        try:
            result = subprocess.run(
                ["bash", str(self.bridge_script), model, prompt],
                capture_output=True,
                text=True,
                timeout=60,
                check=True
            )
            return result.stdout.strip()
        except subprocess.TimeoutExpired:
            print("‚ö†Ô∏è  Gemini call timed out, falling back to mock")
            return self._mock_response(model, prompt)
        except subprocess.CalledProcessError as e:
            print(f"‚ö†Ô∏è  Gemini call failed: {e.stderr}, falling back to mock")
            return self._mock_response(model, prompt)
        except Exception as e:
            print(f"‚ö†Ô∏è  Unexpected error: {str(e)}, falling back to mock")
            return self._mock_response(model, prompt)

    def _mock_response(self, model: str, prompt: str) -> str:
        """Mock –æ—Ç–≤–µ—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –±–µ–∑ —Ä–µ–∞–ª—å–Ω–æ–≥–æ API"""
        return f"""[MOCK RESPONSE from {model.upper()}]

–†–µ–∑—é–º–µ –ø—Ä–æ–±–ª–µ–º:
–ù–∞ –æ—Å–Ω–æ–≤–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —É—è–∑–≤–∏–º–æ—Å—Ç–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏,
–≤–∫–ª—é—á–∞—è hardcoded –ø–∞—Ä–æ–ª–∏ –∏ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ SQL injection —Ç–æ—á–∫–∏. –¢–∞–∫–∂–µ –≤—ã—è–≤–ª–µ–Ω—ã
–ø—Ä–æ–±–ª–µ–º—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å –Ω–µ–æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º–∏.

–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (–ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω—ã):
1. CRITICAL: –ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ —É–±—Ä–∞—Ç—å hardcoded –ø–∞—Ä–æ–ª–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
2. HIGH: –ò—Å–ø—Ä–∞–≤–∏—Ç—å SQL injection —É—è–∑–≤–∏–º–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
3. MEDIUM: –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–ª–æ–∂–µ–Ω–Ω—ã–µ —Ü–∏–∫–ª—ã –≤ API handlers
4. LOW: –î–æ–±–∞–≤–∏—Ç—å cache eviction policy

–ü—Ä–∏–º–µ—Ä—ã –∫–æ–¥–∞:

1. –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ hardcoded password:
```python
# –ë—ã–ª–æ:
PASSWORD = "my_secret_password"

# –î–æ–ª–∂–Ω–æ –±—ã—Ç—å:
import os
PASSWORD = os.getenv("APP_PASSWORD")
```

2. –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ SQL injection:
```python
# –ë—ã–ª–æ:
cursor.execute(f"SELECT * FROM users WHERE id = {{user_id}}")

# –î–æ–ª–∂–Ω–æ –±—ã—Ç—å:
cursor.execute("SELECT * FROM users WHERE id = ?", (user_id,))
```

3. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ü–∏–∫–ª–∞:
```python
# –ë—ã–ª–æ:
for item in items:
    for user in users:
        if item.user_id == user.id:
            # ...

# –î–æ–ª–∂–Ω–æ –±—ã—Ç—å:
user_map = {{user.id: user for user in users}}
for item in items:
    user = user_map.get(item.user_id)
    if user:
        # ...
```
"""


# ============================================================================
# TOKEN COUNTING
# ============================================================================

def count_tokens(text: str) -> int:
    """
    –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ç–æ–∫–µ–Ω—ã (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è).

    –í —Ä–µ–∞–ª—å–Ω–æ–π –≤–µ—Ä—Å–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç tiktoken.
    –ó–¥–µ—Å—å –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—É—é –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—é: ~4 —Å–∏–º–≤–æ–ª–∞ = 1 —Ç–æ–∫–µ–Ω.
    """
    try:
        import tiktoken
        encoding = tiktoken.get_encoding("cl100k_base")
        return len(encoding.encode(text))
    except ImportError:
        # Fallback: –ø—Ä–æ—Å—Ç–∞—è –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—è
        return len(text) // 4


# ============================================================================
# MAIN WORKFLOW
# ============================================================================

def handle_user_request(user_query: str, project_root: Path, verbose: bool = True, use_mock: bool = False) -> Tuple[str, Dict]:
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è workflow - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

    Workflow:
    1. –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞ (Sonnet) ‚Üí HybridClassifier
    2. –ó–∞–ø—É—Å–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ ‚Üí SmartExecutor
    3. –ê–≥—Ä–µ–≥–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ ‚Üí HybridReportAggregator
    4. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ ‚Üí determine_complexity
    5. –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ ‚Üí select_model
    6. –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ ‚Üí build_llm_prompt
    7. –í—ã–∑–æ–≤ LLM (Flash/Pro) ‚Üí GeminiBridge
    8. –í–æ–∑–≤—Ä–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ + –º–µ—Ç—Ä–∏–∫ + —Ç–∞–±–ª–∏—Ü–∞ —Ä–∞—Å—Ö–æ–¥–∞ —Ç–æ–∫–µ–Ω–æ–≤

    Args:
        user_query: –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        project_root: –∫–æ—Ä–Ω–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ø—Ä–æ–µ–∫—Ç–∞
        verbose: –≤—ã–≤–æ–¥–∏—Ç—å –ª–∏ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —à–∞–≥–∏
        use_mock: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å mock –≤–º–µ—Å—Ç–æ —Ä–µ–∞–ª—å–Ω–æ–≥–æ API

    Returns:
        (llm_response, metrics_dict)
    """
    start_time = time.time()
    metrics = {}

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–∫–µ—Ä–∞ —Ç–æ–∫–µ–Ω–æ–≤
    tracker = TokenTracker()
    task_id = tracker.start_task(user_query)

    if verbose:
        print(f"\n{'='*70}")
        print(f"Starting workflow for query: '{user_query}'")
        print(f"{'='*70}\n")

    # –®–∞–≥ 1: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è (—Å—á–∏—Ç–∞–µ–º –∫–∞–∫ –≤—ã–∑–æ–≤ Sonnet ‚Äî classifier)
    if verbose:
        print("Step 1: Classification...")
    classifier = HybridClassifier()
    classification = classifier.classify(user_query)

    # –¢–æ–∫–µ–Ω—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: –≤—Ö–æ–¥–Ω–æ–π –∑–∞–ø—Ä–æ—Å + —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    classify_input_tokens = count_tokens(user_query)
    classify_output_tokens = count_tokens(json.dumps({
        "type": classification.primary_type.value,
        "confidence": classification.confidence,
        "tools": classification.tools,
    }, ensure_ascii=False))
    tracker.record_call(task_id, model="sonnet", role="classifier",
                        input_tokens=classify_input_tokens, output_tokens=classify_output_tokens)

    if verbose:
        print(f"   Type: {classification.primary_type.value}")
        print(f"   Confidence: {classification.confidence:.2f}")
        print(f"   Tools: {', '.join(classification.tools)}")
        print(f"   Scope: {classification.scope}")
        print(f"   Keywords: {', '.join(classification.keywords)}\n")

    # –®–∞–≥ 2: –ó–∞–ø—É—Å–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ (–ª–æ–∫–∞–ª—å–Ω—ã–π, –±–µ–∑ LLM)
    if verbose:
        print("Step 2: Executing tools...")
    executor = SmartExecutor(project_root)
    executor_results = executor.execute(classification)

    if verbose:
        print(f"   Issues found: {len(executor_results['issues'])}")
        print(f"   Execution time: {executor_results['metrics']['execution_time_ms']}ms\n")

    # –®–∞–≥ 3: –ê–≥—Ä–µ–≥–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ (–ª–æ–∫–∞–ª—å–Ω—ã–π, –±–µ–∑ LLM)
    if verbose:
        print("Step 3: Aggregating report...")
    aggregator = HybridReportAggregator()
    report = aggregator.aggregate(classification, executor_results)

    report_json = json.dumps({
        "summary": report.summary,
        "issues": [asdict(issue) for issue in report.issues],
        "metrics": report.metrics,
    }, ensure_ascii=False)
    report_tokens = count_tokens(report_json)

    if verbose:
        print(f"   Summary: {report.summary}")
        print(f"   Report size: {report_tokens} tokens\n")

    metrics["report_tokens"] = report_tokens

    # –®–∞–≥ 4: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
    if verbose:
        print("Step 4: Determining complexity...")
    complexity = determine_complexity(report)

    if verbose:
        print(f"   Complexity: {complexity.value}\n")

    metrics["complexity"] = complexity.value

    # –®–∞–≥ 5: –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
    if verbose:
        print("Step 5: Selecting model...")
    model = select_model(complexity)

    if verbose:
        print(f"   Selected model: {model}")
        model_costs = {
            "flash": "$0.50/$3.00 per 1M tokens",
            "pro": "$2.00/$12.00 per 1M tokens",
            "opus": "$15/$75 per 1M tokens (no delegation)",
        }
        print(f"   Cost: {model_costs.get(model, 'unknown')}\n")

    metrics["model"] = model

    # –®–∞–≥ 6: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞
    if verbose:
        print("Step 6: Building LLM prompt...")
    llm_prompt = build_llm_prompt(user_query, report, classification)
    prompt_tokens = count_tokens(llm_prompt)

    if verbose:
        print(f"   Prompt size: {prompt_tokens} tokens\n")

    metrics["prompt_tokens"] = prompt_tokens

    # –®–∞–≥ 7: –í—ã–∑–æ–≤ LLM (Flash –∏–ª–∏ Pro)
    if verbose:
        print("Step 7: Calling LLM...")

    bridge = GeminiBridge(use_mock=use_mock)
    llm_response = bridge.call(model, llm_prompt)
    response_tokens = count_tokens(llm_response)

    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤—ã–∑–æ–≤ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è
    tracker.record_call(task_id, model=model, role="executor",
                        input_tokens=prompt_tokens, output_tokens=response_tokens)

    if verbose:
        print(f"   Response size: {response_tokens} tokens\n")

    metrics["response_tokens"] = response_tokens

    # –®–∞–≥ 8: –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è Sonnet (–ø–æ–¥—Å—á—ë—Ç —Ç–æ–∫–µ–Ω–æ–≤ –ø—Ä–æ–≤–µ—Ä–∫–∏)
    verify_input_tokens = count_tokens(llm_response[:500])  # Sonnet –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞—á–∞–ª–æ –æ—Ç–≤–µ—Ç–∞
    verify_output_tokens = count_tokens("APPROVED")
    tracker.record_call(task_id, model="sonnet", role="verifier",
                        input_tokens=verify_input_tokens, output_tokens=verify_output_tokens)

    # –§–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    end_time = time.time()
    total_time = end_time - start_time
    metrics["total_time_seconds"] = round(total_time, 2)
    metrics["total_tokens"] = prompt_tokens + response_tokens

    # –ó–∞–≤–µ—Ä—à–∞–µ–º –∑–∞–¥–∞—á—É –≤ —Ç—Ä–µ–∫–µ—Ä–µ –∏ –ø–µ—á–∞—Ç–∞–µ–º —Ç–∞–±–ª–∏—Ü—É
    tracker.finish_task(task_id, complexity=complexity.value)
    metrics["task_id"] = task_id

    if verbose:
        print(f"Workflow completed in {total_time:.2f}s")
        tracker.print_task_summary(task_id)

    return llm_response, metrics


# ============================================================================
# CLI INTERFACE
# ============================================================================

def main():
    """CLI interface –¥–ª—è workflow –∏ –æ—Ç—á—ë—Ç–æ–≤ –ø–æ —Ç–æ–∫–µ–Ω–∞–º"""
    parser = argparse.ArgumentParser(
        description="PT_Standart Main Workflow - Intelligent Code Analysis",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  %(prog)s "–ø—Ä–æ–≤–µ—Ä—å –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å auth –º–æ–¥—É–ª—è"
  %(prog)s "–æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å API" --mock
  %(prog)s --report                    # –¥–Ω–µ–≤–Ω–æ–π –æ—Ç—á—ë—Ç –ø–æ —Ç–æ–∫–µ–Ω–∞–º
  %(prog)s --report --date 2026-02-10  # –æ—Ç—á—ë—Ç –∑–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –¥–µ–Ω—å
  %(prog)s --report --total            # –æ–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
  %(prog)s --report --last 5           # –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 –∑–∞–¥–∞—á
        """
    )

    parser.add_argument(
        "query",
        nargs="?",
        default=None,
        help="–ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–Ω–∞ —Ä—É—Å—Å–∫–æ–º –∏–ª–∏ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º)"
    )

    parser.add_argument(
        "--project-root",
        type=Path,
        default=Path.cwd(),
        help="–ö–æ—Ä–Ω–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ø—Ä–æ–µ–∫—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: —Ç–µ–∫—É—â–∞—è)"
    )

    parser.add_argument(
        "--quiet",
        action="store_true",
        help="–ù–µ –≤—ã–≤–æ–¥–∏—Ç—å –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —à–∞–≥–∏"
    )

    parser.add_argument(
        "--json",
        action="store_true",
        help="–í—ã–≤–µ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ"
    )

    parser.add_argument(
        "--mock",
        action="store_true",
        help="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å mock –æ—Ç–≤–µ—Ç—ã –≤–º–µ—Å—Ç–æ —Ä–µ–∞–ª—å–Ω–æ–≥–æ Gemini API"
    )

    # –ö–æ–º–∞–Ω–¥—ã –æ—Ç—á—ë—Ç–æ–≤
    parser.add_argument(
        "--report",
        action="store_true",
        help="–ü–æ–∫–∞–∑–∞—Ç—å –æ—Ç—á—ë—Ç –ø–æ —Ä–∞—Å—Ö–æ–¥—É —Ç–æ–∫–µ–Ω–æ–≤ (–≤–º–µ—Å—Ç–æ –∑–∞–ø—É—Å–∫–∞ –∑–∞–¥–∞—á–∏)"
    )

    parser.add_argument(
        "--date",
        type=str,
        default=None,
        help="–î–∞—Ç–∞ –¥–ª—è –æ—Ç—á—ë—Ç–∞ (YYYY-MM-DD)"
    )

    parser.add_argument(
        "--total",
        action="store_true",
        help="–û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞ –≤—Å—ë –≤—Ä–µ–º—è"
    )

    parser.add_argument(
        "--last",
        type=int,
        default=0,
        help="–ü–æ–∫–∞–∑–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –∑–∞–¥–∞—á —Å –¥–µ—Ç–∞–ª—è–º–∏"
    )

    args = parser.parse_args()

    # –†–µ–∂–∏–º –æ—Ç—á—ë—Ç–∞
    if args.report or args.total or args.last > 0:
        tracker = TokenTracker()
        if args.total:
            tracker.print_total_stats()
        elif args.last > 0:
            with tracker._conn() as conn:
                tasks = conn.execute(
                    "SELECT task_id FROM tasks ORDER BY started_at DESC LIMIT ?",
                    (args.last,),
                ).fetchall()
            for t in reversed(tasks):
                tracker.print_task_summary(t["task_id"])
        else:
            from datetime import date
            target_date = date.fromisoformat(args.date) if args.date else date.today()
            tracker.print_daily_report(target_date)
        return

    # –†–µ–∂–∏–º –∑–∞–¥–∞—á–∏
    if not args.query:
        parser.error("–£–∫–∞–∂–∏—Ç–µ –∑–∞–ø—Ä–æ—Å –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ --report –¥–ª—è –æ—Ç—á—ë—Ç–∞")

    response, metrics = handle_user_request(
        args.query,
        args.project_root,
        verbose=not args.quiet,
        use_mock=args.mock
    )

    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    if args.json:
        output = {
            "response": response,
            "metrics": metrics,
        }
        print(json.dumps(output, indent=2, ensure_ascii=False))
    else:
        print("\n" + "="*70)
        print("LLM RESPONSE:")
        print("="*70)
        print(response)
        print("="*70 + "\n")


if __name__ == "__main__":
    main()
